{"cells":[{"cell_type":"markdown","metadata":{"id":"VcQufrWvfY1J"},"source":["## Google Colab setup (don't run locally)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ld1DehvfmVE","outputId":"919d0549-7944-419b-da85-1947fcdc7805","executionInfo":{"status":"ok","timestamp":1743093918551,"user_tz":240,"elapsed":74712,"user":{"displayName":"Jade S","userId":"08462326512389871838"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Dataset URL: https://www.kaggle.com/datasets/xhlulu/leafsnap-dataset\n","License(s): copyright-authors\n"]}],"source":["from google.colab import drive\n","import os\n","import shutil\n","\n","# Mount drive to colab\n","drive.mount('/content/drive', force_remount=True)\n","\n","# setting up paths\n","path_to_project_files = '/content/drive/MyDrive/School/Homework/Spring2025/DL/Project/'\n","existing = os.path.join(path_to_project_files, 'kaggle.json')\n","path_to_colab_utils = '/root/.kaggle'\n","target = os.path.join(path_to_colab_utils, 'kaggle.json')\n","\n","# move the key to the colab root\n","os.makedirs(path_to_colab_utils, exist_ok=True)\n","shutil.copy(existing, target)\n","os.chmod(target, 600)\n","\n","# download the data into /content (which is temporary)\n","!kaggle datasets download -d xhlulu/leafsnap-dataset -p /content --unzip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pojg5BTgiA2x"},"outputs":[],"source":["import sys\n","\n","# Edit this path to where you've uploaded the repo files, so the imports work.\n","sys.path.append('/content/drive/MyDrive/School/Homework/Spring2025/DL/Project/')"]},{"cell_type":"markdown","metadata":{"id":"VZ6t5flAg_L3"},"source":["## Library Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2wCOwrEg_L7"},"outputs":[],"source":["from autoencoder import *\n","from dataloader import *\n","from cnn import *\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import v2\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vHlyC5Vg_L8"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def showTensorInNotebook(tensor):\n","    \"\"\"\n","    This takes a (3[RGB], H, W) tensor in R[0.0, 1.0] and displays it with matplotlib.\n","    \"\"\"\n","    image = tensor.detach().cpu().numpy().transpose(1,2,0) # move the channel axis to the end, because PIL and matplotlib hate each other\n","    plt.imshow(image)\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qlvsRzNOrXsT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743093922202,"user_tz":240,"elapsed":46,"user":{"displayName":"Jade S","userId":"08462326512389871838"}},"outputId":"429135d8-6461-4b05-daa1-86bc2672edf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"markdown","metadata":{"id":"B17GtXW4g_L9"},"source":["## Building the data loader"]},{"cell_type":"markdown","metadata":{"id":"Snd7PueTg_L9"},"source":["These are transforms that allow us to ingest the image tensors with some extra confusion at training time. `processor` makes the data loader spit out tensors, and `noiser` adds Gaussian noise."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"ZBLCG5lig_L9","executionInfo":{"status":"ok","timestamp":1743109480629,"user_tz":240,"elapsed":5,"user":{"displayName":"Jade S","userId":"08462326512389871838"}}},"outputs":[],"source":["# This just processes the images.\n","NOISE_RATIO = 0.1\n","H, W = 128, 128\n","\n","processor = v2.Compose([\n","    v2.PILToTensor(), # the LeafsnapDataset class gives PIL Images, convert to torch Tensor\n","    v2.RandomRotation(degrees=(-90, 90)),\n","    v2.Resize((H, W)), # resize\n","    lambda x: x / 255.0, # convert N[0, 255] to R[0.0, 1.0]\n","    lambda x: torch.clip(x + NOISE_RATIO*torch.randn_like(x), 0.0, 1.0), # add noise\n","])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"frUcSFc1g_L-"},"outputs":[],"source":["BATCH_SIZE = 64\n","\n","root_directory = os.path.join(os.getcwd(), 'leafsnap-dataset') # you make need to edit this path to work, though, it works on Colab by default and works locally if you keep the dataset at the root of the repo\n","image_paths_file = os.path.join(path_to_project_files, \"1rev.txt\")\n","dataset = LeafsnapDataset(image_paths_file, root_directory, use_segmented=True, source=\"field\", transform=processor)\n","dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"FaLBO6h8g_L-"},"source":["## Training the Convolutional Neural Network (CNN)"]},{"cell_type":"markdown","metadata":{"id":"WK2Yd5Nwg_L_"},"source":["This model uses a modified version of ResNet from Homework 2. It specifically is a version of ResNet34, with kernel size raised to 5, and skip layers at sizes 32, 64, and 128. Images have been downscaled to 128x128, and the segmentation image is used as a 4th layer, resulting in an input size of 4x128x128."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"693oRWNdg_L_","outputId":"148f0a88-d914-413e-c0af-5e48e678d3d3","executionInfo":{"status":"ok","timestamp":1743108965525,"user_tz":240,"elapsed":8976751,"user":{"displayName":"Jade S","userId":"08462326512389871838"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1/25: 100%|██████████| 121/121 [10:20<00:00,  5.13s/it, batch=121/121, loss=5.03]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 0 loss: 5.439360906269925\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2/25: 100%|██████████| 121/121 [10:11<00:00,  5.05s/it, batch=121/121, loss=4.53]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1 loss: 4.6623787407047494\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3/25: 100%|██████████| 121/121 [10:07<00:00,  5.02s/it, batch=121/121, loss=3.9]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2 loss: 4.2863246369953\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4/25: 100%|██████████| 121/121 [10:10<00:00,  5.05s/it, batch=121/121, loss=3.94]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 3 loss: 3.9604296112848707\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5/25: 100%|██████████| 121/121 [10:07<00:00,  5.02s/it, batch=121/121, loss=3.53]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 4 loss: 3.696912062069601\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 6/25: 100%|██████████| 121/121 [10:09<00:00,  5.03s/it, batch=121/121, loss=3.44]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 5 loss: 3.476209532130848\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 7/25: 100%|██████████| 121/121 [10:09<00:00,  5.04s/it, batch=121/121, loss=2.94]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 6 loss: 3.2517955047039946\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 8/25: 100%|██████████| 121/121 [10:09<00:00,  5.04s/it, batch=121/121, loss=2.6]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 7 loss: 3.0985418449748647\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 9/25: 100%|██████████| 121/121 [10:06<00:00,  5.01s/it, batch=121/121, loss=3.06]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 8 loss: 2.925561335461199\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/25: 100%|██████████| 121/121 [10:03<00:00,  4.99s/it, batch=121/121, loss=2.76]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 loss: 2.771792951694205\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/25: 100%|██████████| 121/121 [10:04<00:00,  4.99s/it, batch=121/121, loss=3.01]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 loss: 2.6711466213888375\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/25: 100%|██████████| 121/121 [10:03<00:00,  4.98s/it, batch=121/121, loss=2.56]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11 loss: 2.5510173375941507\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/25: 100%|██████████| 121/121 [10:00<00:00,  4.96s/it, batch=121/121, loss=2.5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12 loss: 2.3933267790423938\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/25: 100%|██████████| 121/121 [09:57<00:00,  4.93s/it, batch=121/121, loss=1.82]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13 loss: 2.276606022819015\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/25: 100%|██████████| 121/121 [09:58<00:00,  4.95s/it, batch=121/121, loss=1.85]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14 loss: 2.2220378887554832\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/25: 100%|██████████| 121/121 [09:59<00:00,  4.95s/it, batch=121/121, loss=2.46]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15 loss: 2.1151350923806183\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/25: 100%|██████████| 121/121 [09:57<00:00,  4.93s/it, batch=121/121, loss=2.32]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16 loss: 2.0452153643300712\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/25: 100%|██████████| 121/121 [09:57<00:00,  4.94s/it, batch=121/121, loss=1.78]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17 loss: 1.9581950863530813\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/25: 100%|██████████| 121/121 [09:55<00:00,  4.93s/it, batch=121/121, loss=2.1]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18 loss: 1.8656652003280387\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/25: 100%|██████████| 121/121 [09:58<00:00,  4.95s/it, batch=121/121, loss=1.71]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19 loss: 1.8020712373670467\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21/25: 100%|██████████| 121/121 [09:55<00:00,  4.92s/it, batch=121/121, loss=1.56]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20 loss: 1.7661464302993017\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 22/25: 100%|██████████| 121/121 [09:49<00:00,  4.88s/it, batch=121/121, loss=1.75]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21 loss: 1.6739214520809078\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 23/25: 100%|██████████| 121/121 [09:51<00:00,  4.88s/it, batch=121/121, loss=1.8]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22 loss: 1.6060193786936359\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 24/25: 100%|██████████| 121/121 [09:51<00:00,  4.89s/it, batch=121/121, loss=1.23]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23 loss: 1.5243614291356615\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 25/25: 100%|██████████| 121/121 [09:48<00:00,  4.87s/it, batch=121/121, loss=1.61]"]},{"output_type":"stream","name":"stdout","text":["Epoch 24 loss: 1.4963856699052922\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model = resnet(4, 185, device=device)\n","\n","train_resnet_model(model, dataloader, 25, .001, device=device)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"sQzs2bGwg_MA","executionInfo":{"status":"ok","timestamp":1743108965688,"user_tz":240,"elapsed":148,"user":{"displayName":"Jade S","userId":"08462326512389871838"}}},"outputs":[],"source":["torch.save(model.state_dict(), path_to_project_files + \"cnn_model.pth\")"]},{"cell_type":"markdown","metadata":{"id":"rVA0iHLeg_MA"},"source":["## Testing the CNN"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"whBbgkVbg_MB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743109480150,"user_tz":240,"elapsed":514444,"user":{"displayName":"Jade S","userId":"08462326512389871838"}},"outputId":"51fc2747-9673-4ca9-f2c9-c4d3344808a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Top-1 Accuracy: 57.87%\n","Top-5 Accuracy: 89.49%\n"]}],"source":["correct_top1 = 0\n","correct_top5 = 0\n","total = 0\n","\n","model.to(device)\n","with torch.no_grad(): # No gradients needed for evaluation\n","    for inputs, labels in dataloader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","\n","        # Top-1 Accuracy\n","        _, predicted = torch.max(outputs, 1)\n","        correct_top1 += (predicted == labels).sum().item()\n","\n","        # Top-5 Accuracy\n","        top5_preds = torch.topk(outputs, 5, dim=1).indices\n","        correct_top5 += torch.sum(top5_preds.eq(labels.view(-1, 1))).item()\n","\n","        total += labels.size(0)\n","\n","# Compute accuracies\n","top1_accuracy = 100 * correct_top1 / total\n","top5_accuracy = 100 * correct_top5 / total\n","\n","print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\n","print(f\"Top-5 Accuracy: {top5_accuracy:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"b_t7sGbPWNOn"},"source":["After various tweaks, I'm very happy with the current training accuracy of the CNN model, especially for the first check-in. Running at a 90% Top-5 accuracy is excellent, although there is certainly some more hyperparameter tweaking to be done. I may also test changing the model's structure, adding techniques such as dropout that have been used in other models for similar purposes. I would like to reach 80% Top-1 accuracy by the end."]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}