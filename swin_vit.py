# -*- coding: utf-8 -*-
"""Swin_ViT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13xyeU9Bp8V9294TC7zxbAKhh_m5T8J0u

## downloading the data set
"""

# note: i'll fix this later i was having issues w the dataloader and kaggle file so i just directly uploaded them here
from google.colab import drive
import os
import shutil

# files.upload()

# #mount to drive
drive.mount('/content/drive', force_remount=True)
# setting up paths
path_to_project_files = '/content/drive/MyDrive/dl2025spr/DeepLearning/'
existing = os.path.join(path_to_project_files, 'kaggle.json')
path_to_colab_utils = '/root/.kaggle'
target = os.path.join(path_to_colab_utils, 'kaggle.json')

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d xhlulu/leafsnap-dataset
!unzip leafsnap-dataset.zip

"""# Set up the data loader

creating the dataset and dataloader
"""

# # # it wasnt working so im manually uploading it
# from google.colab import files
# files.upload()

"""imports"""

from dataloader import *

import os
import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
# from dataloader import LeafsnapDataset

# additional imports for the SWIN transformer
import torch.nn as nn
import timm # has the pre-trained swim models

"""define image transformations"""

# transformer
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images
    transforms.ToTensor(),  # Convert images to tensors
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize
])

"""# building data loader

inialize the data set
"""

# # it wasnt working so im manually uploading it
# leaf snap dataset
# from google.colab import files
# files.upload()

root_directory = "/content/leafsnap-dataset/"
image_paths_file = root_directory + "leafsnap-dataset-images.txt"

dataset = LeafsnapDataset(image_paths_file, root_directory, use_segmented=False, transform=transform)

"""build the dataloader"""

dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)

"""verifying that the dataloader is workin [debugging to see what it shows]

"""

data_iter = iter(dataloader)
images, labels = next(data_iter)
print(f"Batch size: {images.shape}, Labels: {labels}")

"""Leadsnap Dataset modification (80/20 split)

"""

class LeafsnapDataset(Dataset):
  def init__(self, image_path, root_folder, image_list_file, ise_segmented=False, transform=None):
    self.root_directory = root_folder
    self.transform = transform

    # reading the list of image paths from the file in git
    with open(os.path.join(root_folder, image_list_file), 'r') as f:
      image_paths = f.read().splitlines()

    # getting the main image info from the csv file
    self.image_info = pd.read_csv(image_path, sep='\t')
    # we then filter the image_info to inlcude only paths from the file
    self.image_info = self.image_info[self.image_info['image_path'].isin(image_paths)]
    self.image_info = self.image_info.reset_index(drop=True)

    # label mapping
    label_hashmap = {}
    species_set = set(sorted(self.image_info['species'].unique()))

    for i, species in enumerate(species_set):
      label_hashmap[species] = i

    # convert the species in to numeric labels
    self.labels = [label_hashmap[species] for species in self.image_info['species']]
    # determine which image path column to use
    self.img_path_col = 'segmented_path' if use_segmented else 'image_path'

  def _len_(self):
    return len(self.image_info)

  def _getitem_(self, idx):
    # constructing the full image path
    img_name = os.path.join(self.root_directory, self.image_info.loc[idx, self_img_path_col])

    # open and transform image
    image = Image.open(img_name).convert('RGB')
    if self.transform:
      image - self.transform(image)
    return image, self.labels[idx]

"""## Vision Transformer (ViT) implementation

install needed libraries
"""

!pip install torch torchvision timm

"""load pre-trained ViT model"""

import timm
import torch.nn as nn
## defining the vision transformer
class ViTLeafClassifier(nn.Module):
    def __init__(self, num_classes=185):
        super(ViTLeafClassifier, self).__init__()

        # vision transformer used
        # self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)  # Load ViT with pre-trained weights
        # self.vit.head = nn.Linear(self.vit.head.in_features, num_classes)  # Modify classifier for 185 leaf classes

        # updated: to make it a swin model instead of vision transformer
        self.vit = timm.create_model("swin_tiny_patch4_window7_224", pretrained=True, num_classes=185)

    def forward(self, x):
        return self.vit(x)

"""# Train the model

this is just a sanity check to see if its working like needed - takes a batch from dataloader > undoes the imageNet normalization - plots 4 random images
"""

import matplotlib.pyplot as plt

# Get one batch from the train dataloader
data_iter = iter(dataloader)
images, labels = next(data_iter)

num_images_to_show = 4
# Plot a few sample images with their labels
plt.figure(figsize=(12, 6))
for idx in range(num_images_to_show):
    img = images[idx].cpu()
    img = img * torch.tensor([0.229, 0.224, 0.225]).view(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)  # Undo normalization
    img = img.permute(1, 2, 0).numpy()  # (C, H, W) --> (H, W, C)
    img = img.clip(0, 1)

    plt.subplot(1, num_images_to_show, idx+1)
    plt.imshow(img)
    plt.title(f"Label: {labels[idx].item()}")
    plt.axis('off')

plt.show()

# i have trained it like 3 times already and it randomly crashes or my laptop does, i will finish training in a bit and push again ik colab hates me rn

# training loop
# Define the device
import torch
from tqdm import tqdm # for the bar

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# Initialize model, loss function, and optimizer
model = ViTLeafClassifier(num_classes=185).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)

# Training loop
num_epochs = 10
print(f"\n Starting Training on {device}\n")

for epoch in range(num_epochs):
    model.train()

    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')

    running_loss = 0.0
    correct = 0
    total = 0

    # print(f"\n Epoch {epoch+1}/{num_epochs}")

    for batch_idx, (images, labels) in enumerate(dataloader):
        images, labels = images.to(device), labels.to(device) # move data ti device

        optimizer.zero_grad() # we zero the parameter gradients
        # forward pass
        outputs = model(images)

        # loss = criterion(outputs, labels)
        labels = labels.long()
        loss = criterion(outputs, labels)
        # backward pass
        loss.backward()
        optimizer.step()

        # update the stats
        running_loss += loss.item()

        # track accuracy
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

        # update the progress bar
        # Print updates every 10 batches
        if (batch_idx + 1) % 10 == 0 or batch_idx == 0:
            print(f"  Batch {batch_idx+1}/{len(dataloader)} | Loss: {loss.item():.4f} | Running Avg Loss: {running_loss / (batch_idx + 1):.4f}")

    # summary
    epoch_loss = running_loss / len(dataloader)
    epoch_acc = 100 * correct / total
    print(f"\n Epoch {epoch+1} Finished - Avg Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%")

print("\n Training Complete!")

"""^ had to end training early because I ran out of tokens on github colab.

# Evaluating the model
"""

# top-1 accuracy, top-5 accuracy, and macro f1
from sklearn.metrics import accuracy_score, f1_score
import torch

model.eval()
all_preds = []
all_labels = []
top5_correct = 0
total_samples = 0

with torch.no_grad():
    for images, labels in dataloader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)

        #Top-1 Predictions
        _, top1_preds = torch.max(outputs, 1)
        all_preds.extend(top1_preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

        # Top-5 Accuracy
        top5_preds = torch.topk(outputs, k=5, dim=1).indices  # Get top-5 indices
        top5_correct += torch.sum(top5_preds.eq(labels.view(-1, 1)))  # Count correct top-5
        total_samples += labels.size(0)

#Calculate Metrics
top1_accuracy = accuracy_score(all_labels, all_preds)
top5_accuracy = top5_correct.item() / total_samples
macro_f1 = f1_score(all_labels, all_preds, average='macro')

print(f"Top-1 Accuracy: {top1_accuracy:.4f}") # 60.45
print(f"Top-5 Accuracy: {top5_accuracy:.4f}") # 88.53
print(f"Macro F1 Score: {macro_f1:.4f}") # 59.03

"""Result comparison

ViT Results:
$$\text{Top-1 Accuracy}: 0.6045$$
$$\text{Top-5 Accuracy}: 0.8853$$
$$\text{Macro F1 Score}: 0.59.03$$

Swim Transformer:
$$\text{Top-1 Accuracy}: 0.9248$$
$$\text{Top-5 Accuracy}: 0.9966$$
$$\text{Macro F1 Score}: 0.9257$$

These results could be wrong, possibly because of overfitting or model just memorizing. There could also be a test leakage if the there is an overlap between the test and train images.
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

y_true = []
y_pred = []

model.eval()
with torch.no_grad():
    for images, labels in dataloader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(preds.cpu().numpy())

image_info = pd.read_csv("/content/leafsnap-dataset/leafsnap-dataset-images.txt", sep='\t')
# create index to species mapping
species_to_idx = {species: i for i, species in enumerate(sorted(image_info['species'].unique()))}
idx_to_species = {v: k for k, v in species_to_idx.items()}  # Create reverse mapping

# confusion matrix
cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(idx_to_species.values()))

fig, ax = plt.subplots(figsize=(14, 14))
disp.plot(ax=ax, xticks_rotation='vertical')
plt.title("Confusion Matrix of Swin Transformer on LeafSnap Test Set")
plt.show()

"""The confusion matrix shows the model's performance across 185 leaf species in the LeafSnap test database. Each row is the true species label and each column shows the model's predicted label. The confusion matrix has a strong diagnoal pattern shwoing that Swin Transformer corrrectly predicted majority of the samples for each species. Therefore, the confusion matrix supports the model's reported high accuracy and macro-F1 score.

saving
"""

torch.save(model.state_dict(), "vit_swin__leafsnap.pth")